# American-Sign-Language-Detection-
Sign Language to Text Converter
This project converts American Sign Language (ASL) hand gestures into text using computer vision and machine learning. It leverages MediaPipe for hand tracking, OpenCV for image processing, and a trained ML model for gesture classification. The project also includes an optional Streamlit UI for interactive usage.
ðŸš€ Features
â€¢	Real-time hand tracking using MediaPipe
â€¢	Gesture classification with a trained ML model (model.p)
â€¢	Converts ASL signs into text output
â€¢	Supports live webcam input
â€¢	Easy deployment via Streamlit app
ðŸ“‚ Project Structure
â”œâ”€â”€ asl1.py                # Main script for running the application
â”œâ”€â”€ sign-to-text.ipynb     # Jupyter notebook for sign-to-text pipeline
â”œâ”€â”€ ml_model.ipynb         # Notebook for training ML model
â”œâ”€â”€ model.p                # Pre-trained ML model
â”œâ”€â”€ requirements1.txt      # Dependencies
â””â”€â”€ README.md              # Project documentation
âš™ Installation
1.	Clone this repository
2.	git clone https://github.com/yourusername/sign-to-text.git
3.	cd sign-to-text
4.	Create virtual environment
5.	python -m venv venv
6.	source venv/bin/activate   # On Linux/Mac
7.	venv\Scripts\activate      # On Windows
8.	Install dependencies
9.	pip install -r requirements1.txt
â–¶ Usage
Run with Python Script
python asl1.py
Run Jupyter Notebook
Open either sign-to-text.ipynb or ml_model.ipynb in Jupyter and run cells step by step.
Run with Streamlit
streamlit run asl1.py
ðŸ›  Tech Stack
â€¢	Python
â€¢	OpenCV â€“ image processing
â€¢	MediaPipe â€“ hand tracking
â€¢	Scikit-learn / PyTorch â€“ ML model training
â€¢	Streamlit â€“ web app interface
â€¢	NumPy, Pandas, SciPy â€“ data handling
ðŸ“Š Model Training
â€¢	Training done in ml_model.ipynb
â€¢	The trained model is saved as model.p
â€¢	Uses scikit-learn for classification
ðŸ“Œ Requirements
From requirements1.txt:
â€¢	mediapipe
â€¢	opencv-python & opencv-contrib-python
â€¢	scikit-learn, scipy
â€¢	torch
â€¢	numpy, pandas, matplotlib
â€¢	streamlit
â€¢	PyAudio
â€¢	python-dotenv
â€¢	google-generativeai (optional integration)
ðŸŽ¯ Future Improvements
â€¢	Add support for more ASL gestures
â€¢	Improve accuracy with deep learning models (CNNs, RNNs)
â€¢	Support multi-hand gestures
â€¢	Add text-to-speechÂ output
